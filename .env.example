# ============================================================
# WATUS JETSON — Skonsolidowana Konfiguracja Środowiskowa
# ============================================================
# Ten plik zawiera WSZYSTKIE zmienne środowiskowe dla projektu.
# Skopiuj go jako .env i uzupełnij wartości.
# ============================================================


# ============================
# === Konfiguracja LLM API ===
# ============================

# Klucz API do Google Gemini.
# Pobierz z: https://aistudio.google.com/
# (WYMAGANE)
GEMINI_API_KEY=
# Model Gemini (np. "gemini-flash-latest", "gemini-flash-lite-latest").
# (WYMAGANE)
GEMINI_MODEL=

# Klucz API do OpenAI.
OPENAI_API_KEY=
# Model OpenAI (np. "gpt-4o-mini").
OPENAI_MODEL=

# Model Anthropic (np. "claude-3-5-sonnet").
ANTHROPIC_MODEL=
# Klucz API do Anthropic.
ANTHROPIC_API_KEY=


# ============================================
# === Konfiguracja Syntezy Mowy (TTS) ===
# ============================================
# Wybór silnika TTS.
# Możliwe wartości:
#   - "piper": Lokalny, szybki, działa offline. Wymaga pliku modelu ONNX.
#   - "gemini": Zdalny (Google Gemini), wyższa jakość, wymaga klucza API.
#   - "inworld": Zdalny (Inworld AI), niska latencja, wymaga klucza API.
# (WYMAGANA konfiguracja jednego z tych)
TTS_PROVIDER=gemini

# --- Piper TTS (jeśli TTS_PROVIDER=piper) ---
# Ścieżka do modelu Piper ONNX.
PIPER_MODEL_PATH=models/piper/voices/pl_PL-jarvis-medium.onnx
# Częstotliwość próbkowania modelu Piper (musi pasować do modelu).
PIPER_SAMPLE_RATE=22050
# Ścieżka do binarki Piper (opcjonalnie, jeśli nie w PATH).
PIPER_BIN=
# Ścieżka do pliku konfiguracyjnego Piper (.onnx.json).
PIPER_CONFIG=

# --- Gemini TTS (jeśli TTS_PROVIDER=gemini) ---
# Głos Gemini. Przykłady: "Achird", "Puck", "Charon", "Kore", "Fenrir".
GEMINI_VOICE=Achird

# --- Inworld TTS (jeśli TTS_PROVIDER=inworld) ---
# Klucz API w formacie Base64.
# Pobierz z: https://platform.inworld.ai/
INWORLD_API_KEY=
# Model Inworld TTS.
# Możliwe wartości: "inworld-tts-1", "inworld-tts-1-max", "inworld-tts-1.5-mini", "inworld-tts-1.5-max"
INWORLD_MODEL=inworld-tts-1.5-max
# Głos Inworld. Przykłady: "Szymon", "Wojtek", itp.
# Pełna lista: https://platform.inworld.ai/tts-playground
INWORLD_VOICE=Szymon
# Częstotliwość próbkowania audio (Hz). Domyślnie 48000.
INWORLD_SAMPLE_RATE=48000
# Prędkość mówienia (0.5 - 1.5). Domyślnie 1.0.
INWORLD_SPEED=1.0

# --- XTTS-v2 (eksperymentalne) ---
# Ścieżka do modelu XTTS (opcjonalnie).
XTTS_MODEL_PATH=
# Plik referencyjny głosu dla klonowania.
XTTS_SPEAKER_WAV=models/xtts/ref.wav
# Język XTTS.
XTTS_LANGUAGE=pl


# ================================================
# === Konfiguracja Rozpoznawania Mowy (STT) ===
# ================================================
# Wybór silnika STT.
# Możliwe wartości:
#   - "local": Lokalny Whisper (faster-whisper).
#   - "groq": Zdalny Groq API.
# (WYMAGANA konfiguracja jednego z tych)
STT_PROVIDER=local

# --- Groq STT (jeśli STT_PROVIDER=groq) ---
GROQ_API_KEY=
GROQ_MODEL=whisper-large-v3

# --- Faster Whisper / Whisper (jeśli STT_PROVIDER=local) ---
# Uproszczona konfiguracja (WHISPER_SIZE + WHISPER_DEVICE_TYPE):
# Rozmiar modelu: "tiny", "base", "small", "medium", "large", "large-v3".
WHISPER_SIZE=medium
# Typ urządzenia: "cpu" lub "gpu".
WHISPER_DEVICE_TYPE=cpu

# Zaawansowana konfiguracja (nadpisuje uproszczoną, jeśli ustawione):
# Pełna ścieżka/nazwa modelu Whisper.
WHISPER_MODEL=models/whisper/faster-whisper-medium
# Urządzenie: "cpu" lub "cuda".
WHISPER_DEVICE=cpu
# Precyzja obliczeń: "int8", "float16" (GPU), "float32".
WHISPER_COMPUTE=int8
# Liczba workerów Whisper.
WHISPER_NUM_WORKERS=1
# Liczba wątków CPU.
WATUS_CPU_THREADS=


# ===========================================
# === Słowa Wybudzające (Wake Words) ===
# ===========================================
# Lista fraz (oddzielonych przecinkami), które aktywują nasłuchiwanie.
# System ignoruje wielkość liter i interpunkcję przy sprawdzaniu.
WAKE_WORDS=hej watusiu,hej watuszu,hej watusił,kej watusił,hej watośiu,


# ================================
# === Ustawienia Audio i VAD ===
# ================================
# Częstotliwość próbkowania audio (Hz). Domyślnie 16000.
WATUS_SR=16000
# Rozmiar bloku audio (próbki).
WATUS_BLOCKSIZE=160
# ID urządzenia wejściowego (mikrofon). Sprawdź ID poleceniem: python -m sounddevice
WATUS_INPUT_DEVICE=
# ID urządzenia wyjściowego (głośniki).
WATUS_OUTPUT_DEVICE=
# Minimalny poziom głośności (dBFS), powyżej którego zaczyna się detekcja mowy.
# Niższa wartość (np. -50) = większa czułość. Wyższa (np. -20) = mniejsza czułość.
ASR_MIN_DBFS=-45

# Tryb VAD (Voice Activity Detection). Domyślnie 1.
WATUS_VAD_MODE=1
# Minimalna długość segmentu mowy (ms).
WATUS_VAD_MIN_MS=150
# Cisza końcowa (ms) — po ilu ms ciszy uznać koniec wypowiedzi.
WATUS_SIL_MS_END=450
# Liczba ramek w buforze wstępnym.
WATUS_PREBUFFER_FRAMES=15
# Minimalna liczba ramek, aby rozpocząć detekcję.
WATUS_START_MIN_FRAMES=4
# Minimalny dBFS do rozpoczęcia detekcji (domyślnie ASR_MIN_DBFS + 4).
WATUS_START_MIN_DBFS=
# Minimalny czas (ms) przed uznaniem endpointu.
WATUS_MIN_MS_BEFORE_ENDPOINT=500
# Spadek dBFS kończący wypowiedź (0 = wyłączone).
END_AT_DBFS_DROP=0
# Cooldown (ms) między emisjami.
EMIT_COOLDOWN_MS=300
# Maksymalna długość wypowiedzi (ms).
MAX_UTT_MS=6500
# Tolerancja przerw (ms).
WATUS_GAP_TOL_MS=450


# =======================================
# === Weryfikacja Mówcy (Speaker ID) ===
# =======================================
# Włącz/wyłącz weryfikację mówcy (1 = włączone, 0 = wyłączone).
SPEAKER_VERIFY=1
# Próg podobieństwa głosu (0.0 - 1.0). Wyższy = trudniej zaakceptować.
SPEAKER_THRESHOLD=0.64
# Próg "lepki" — ułatwia utrzymanie identyfikacji po pierwszym rozpoznaniu.
SPEAKER_STICKY_THRESHOLD=
# Margines tolerancji (grace).
SPEAKER_GRACE=0.12
# Czas (sekundy) utrzymania "lepkiej" identyfikacji.
SPEAKER_STICKY_SEC=3600
# Minimalny wynik zapisu (enrollment) mówcy.
SPEAKER_MIN_ENROLL_SCORE=0.55
# Minimalny dBFS dla próbki mówcy.
SPEAKER_MIN_DBFS=-40
# Maksymalny dBFS dla próbki mówcy.
SPEAKER_MAX_DBFS=-5
# Próg powrotu mówcy.
SPEAKER_BACK_THRESHOLD=0.56
# Wymagaj dopasowania mówcy (1 = tak, 0 = nie).
SPEAKER_REQUIRE_MATCH=1


# ======================================
# === Komunikacja ZMQ ===
# ======================================
# Adresy gniazd ZMQ do komunikacji między procesami.
ZMQ_PUB_ADDR=tcp://127.0.0.1:7780
ZMQ_SUB_ADDR=tcp://127.0.0.1:7781


# ======================================
# === Konfiguracja Reportera LLM ===
# ======================================
# Adres URL serwera LLM, do którego wysyłane są zapytania.
LLM_HTTP_URL=http://127.0.0.1:8000/api1/process_question
# Limit czasu (timeout) na odpowiedź z serwera LLM (sekundy).
HTTP_TIMEOUT=30.0
# Czas oczekiwania na odpowiedź (sekundy).
WAIT_REPLY_S=0.6


# ======================================
# === Ścieżki i Katalogi ===
# ======================================
# Ścieżka do pliku dialogów.
DIALOG_PATH=data/watus_audio/dialog.jsonl
# Katalog scenariuszy tekstowych.
WATUS_SCENARIOS_DIR=./scenarios_text
# Ścieżka do aktywnego scenariusza.
SCENARIO_ACTIVE_PATH=
# Nazwa kamery.
CAMERA_NAME=cam_front
# Ścieżka do pliku JSONL kamery.
CAMERA_JSONL=data/watus_audio/camera.jsonl
# Okno czasowe kamery (sekundy).
CAMERA_WINDOW_SEC=2.5
# Katalog logów.
LOG_DIR=./


# ===================================
# === YOLO / Model Trainer ===
# ===================================
# Klucz API WandB do logowania treningu (opcjonalnie).
WANDB_API_KEY=
# Eksperymentalny balancer klas (0 = wyłączony, 1 = włączony).
USE_EXPERIMENTAL_BALANCER=0
# Ścieżka do cache HuggingFace (domyślnie dla Jetsona).
HF_HOME=
