================================================================================
OLLAMA BENCHMARK - JETSON ORIN GPU
Data: 2025-12-10 10:32:02
================================================================================

KONFIGURACJA:
- GPU: NVIDIA Orin (nvgpu) - 100% GPU utilization
- CUDA: 12.2
- RAM: 64GB (unified memory)
- Power Mode: 30W (uwaga: MAXN wymaga restartu)
- OLLAMA_FLASH_ATTENTION: w≈ÇƒÖczony
- Prompt testowy: "Napisz kr√≥tkƒÖ bajkƒô o kocie w 3 zdaniach."

================================================================================
WYNIKI BENCHMARKU (posortowane wg tokens/sec)
================================================================================

Model                                              Tok/s   Tokeny  Gen Time  Load Time
----------------------------------------------------------------------------------------
ü•á gemma3:270m                                     50.00       58     1.2s       4.3s
ü•à gemma3:4b                                       11.46      106     9.2s       0.4s
ü•â gpt-oss:20b                                      8.25      352    42.7s     157.5s
   ServiceNow-AI/Apriel-1.5-15b-Thinker:Q4_K_M      4.01      958   238.9s     191.0s
   qwen3:32b                                        1.98      369   186.1s     230.0s
   magistral:latest                                 1.77     1087   612.8s       9.9s
   nemotron:latest                                     -        -        -   HTTP 500
----------------------------------------------------------------------------------------

================================================================================
PODSUMOWANIE
================================================================================

üèÜ NAJSZYBSZY MODEL: gemma3:270m (50.00 tokens/sec)

üìä WSZYSTKIE MODELE PRZETESTOWANE NA 100% GPU (potwierdzone przez `ollama ps`)

‚ö° RANKING WYDAJNO≈öCI:
1. gemma3:270m     - 50.00 tok/s - NAJLEPSZY do szybkich odpowiedzi
2. gemma3:4b       - 11.46 tok/s - dobry balans jako≈õƒá/szybko≈õƒá
3. gpt-oss:20b     -  8.25 tok/s - dobra wydajno≈õƒá dla 20B modelu
4. Apriel-15b      -  4.01 tok/s - solidna wydajno≈õƒá, d≈Çu≈ºsze odpowiedzi
5. qwen3:32b       -  1.98 tok/s - wolny ale najwiƒôkszy (32B)
6. magistral       -  1.77 tok/s - wolny, generuje bardzo d≈Çugie odpowiedzi (1087 tok)

‚ùå PROBLEMY:
- nemotron:latest (42GB) - HTTP 500 (prawdopodobnie brak pamiƒôci dla tak du≈ºego modelu)

üí° UWAGI:
- magistral generuje bardzo d≈Çugie odpowiedzi (1087 token√≥w vs ~100-400 w innych)
- Wiƒôksze modele wymagajƒÖ d≈Çu≈ºszego czasu ≈Çadowania (do 230s dla qwen3:32b)
- Dla szybkich interakcji zalecany: gemma3:270m lub gemma3:4b

================================================================================
